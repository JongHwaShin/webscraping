{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기상청 날씨 데이터 파싱\n",
    "* Beautifulsoup 객체의 find(), find_all() 함수 사용하여 파싱하기\n",
    "* 파싱한 데이터를 dict, list에 저장하기\n",
    "* json file로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp' ##기상청 url\n",
    "\n",
    "res = requests.get(url)\n",
    "\n",
    "if res.ok : \n",
    "    soup = BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "    title_tag = soup.find('title')\n",
    "    # print(title_tag.text)\n",
    "\n",
    "    title_tag_all = soup.find_all('title')\n",
    "    # print(type(title_tag_all))\n",
    "\n",
    "    # for title in title_tag_all:\n",
    "    #     print(type(title.string),type(title.text))\n",
    "    #     print(title.string,title.text)\n",
    "\n",
    "    location_tag = soup.find('location',attrs={'wl_ver':3})  ###find ~ attrs로 속성찾기\n",
    "    # print(location_tag)\n",
    "\n",
    "    location_tag2 = soup.select_one(\"location[wl_ver='3']\") ###select_one ~ 으로 찾기\n",
    "    # print('-------------select_one')\n",
    "    # print(location_tag2)\n",
    "\n",
    "\n",
    "    loc_tag_all = soup.findAll('location',attrs={'wl_ver':3}) #findAll\n",
    "    # print('-----------finaAll')\n",
    "    # # print(loc_tag_all)\n",
    "\n",
    "    loc_tag_all2 = soup.select(\"location[wl_ver='3']\") #select\n",
    "    # print('------------select')\n",
    "    # print(loc_tag_all2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 서울 city의 날씨\n",
    "{\n",
    "    \"province\" : \"서울 인천 경기도\", \"city\" : \"서울\",\n",
    "    \"datas\":[{\"mode\":\"A02\",\"tmEf\":\"2002-01-31 00:00\",\"wf\":\"맑음\"...(생략)\n",
    "    ...\n",
    "    ]\n",
    "\n",
    "\n",
    "}\n",
    " 서울 날씨는 하나의 값이므로 dictionary로 생성\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp' ##기상청 url\n",
    "\n",
    "res = requests.get(url)\n",
    "\n",
    "if res.ok :\n",
    "    soup = BeautifulSoup(res.text,'html.parser')\n",
    "    location_tag = soup.find('location',attrs={'wl_ver':3})\n",
    "    location_dict = {} #dict()\n",
    "\n",
    "\n",
    "    location_dict['province'] = location_tag.find('province').text ##location 밑의 province 를 딕셔너리에 넣는다\n",
    "    #print(location_dict) # = 출력{'province': <province>서울ㆍ인천ㆍ경기도</province>}\n",
    "\n",
    "    location_dict['dict'] = location_tag.find('city').text\n",
    "    #print(location_dict) # 출력 {'province': '서울ㆍ인천ㆍ경기도', 'dict': '서울'}\n",
    "\n",
    "\n",
    "    data_tags = location_tag.find_all('data') ##data 태그는 location 밑에있는 태그이다, 여러개라서 find_all()\n",
    "    data_list = []\n",
    "\n",
    "    for data_tag in data_tags:\n",
    "        data_dict = {} ## 리스트안에 들어갈 딕셔너리를 만든다\n",
    "        data_dict['mode'] = data_tag.find('mode').text  ##data 태그 밑에있는 mode 를 찾는다\n",
    "        data_dict['tmef'] = data_tag.find('tmef').text\n",
    "        data_dict['wf'] = data_tag.find('wf').text\n",
    "        data_dict['tmn'] = data_tag.find('tmn').text\n",
    "\n",
    "        data_list.append(data_dict)\n",
    "\n",
    "    location_dict['datas'] = data_list\n",
    "    # print(location_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 전국\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp' ##기상청 url\n",
    "\n",
    "res = requests.get(url)\n",
    "\n",
    "if res.ok :\n",
    "    soup = BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "    location_tags = soup.find_all('location',attrs={'wl_ver':3})\n",
    "\n",
    "    location_list = []\n",
    "    for location_tag in location_tags:\n",
    "        location_dict = {}\n",
    "        location_dict['province'] = location_tag.find('province').text\n",
    "\n",
    "\n",
    "        location_dict['city'] = location_tag.find('city').text\n",
    "    #print(location_dict) # 출력 {'province': '서울ㆍ인천ㆍ경기도', 'dict': '서울'}\n",
    "\n",
    "\n",
    "        data_tags = location_tag.find_all('data') ##data 태그는 location 밑에있는 태그이다, 여러개라서 find_all()\n",
    "        data_list = []\n",
    "\n",
    "        for data_tag in data_tags:\n",
    "            data_dict = {} ## 리스트안에 들어갈 딕셔너리를 만든다\n",
    "            data_dict['mode'] = data_tag.find('mode').text  ##data 태그 밑에있는 mode 를 찾는다\n",
    "            data_dict['tmef'] = data_tag.find('tmef').text\n",
    "            data_dict['wf'] = data_tag.find('wf').text\n",
    "            data_dict['tmn'] = data_tag.find('tmn').text\n",
    "\n",
    "            data_list.append(data_dict)\n",
    "\n",
    "            location_dict['datas'] = data_list\n",
    "            location_list.append(location_dict)\n",
    "\n",
    "    # print(location_list)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## location_list 를 json파일로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/weather.json','w') as file:\n",
    "    json.dump(location_list,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/weather.json\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m,encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m      3\u001B[0m     content \u001B[38;5;241m=\u001B[39m file\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m----> 4\u001B[0m     json_content \u001B[38;5;241m=\u001B[39m \u001B[43mjson\u001B[49m\u001B[38;5;241m.\u001B[39mloads(content)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "## json file 읽기\n",
    "with open('data/weather.json','r',encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "    json_content = json.loads(content)\n",
    "\n",
    "# print(json_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a508bddc2100ee399c9449bab23c2fcacd162a32e9510b6def136ab72811252"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('test': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}